import numpy as np

# AdamStelmaszczyk (2020). Github: https://github.com/AdamStelmaszczyk/dqn
# Andrychowicz, M., Wolski, F., Ray, A., Schneider, J., Fong, R., Welinder, P.,
# McGrew, B., Tobin, J., Abbeel, P., and Zaremba, W. (2017). ‘Hindisght Experience Replay’.
#[Online]. Available at: https://arxiv.org/abs/1707.01495 [Accessed 2nd April 2021]
# TianhongDai (2021). Github : https://github.com/TianhongDai/hindsight-experience-replay
# Hemilpanchiwala (2021). Github: https://github.com/hemilpanchiwala/Hindsight-Experience-Replay
# Kwea123 (2018). Github: https://github.com/kwea123/hindsight_experience_replay


class HindsightExperienceReplayMemory(object):
    """
    Hindsight Experience replay - Takes size, input dimensions and number of actions as parameters
    """
    def __init__(self, memory_size, input_dims, n_actions):
        super(HindsightExperienceReplayMemory, self).__init__()
        self.max_mem_size = memory_size
        self.counter = 0

        # initializes the state, next_state, action, reward, and terminal experience memory
        self.state_mem = np.zeros((memory_size, input_dims), dtype=np.float32)
        self.next_state_memory = np.zeros((memory_size, input_dims), dtype=np.float32)
        self.reward_mem = np.zeros(memory_size, dtype=np.float32)
        self.action_mem = np.zeros(memory_size, dtype=np.float32)
        self.terminal_mem = np.zeros(memory_size, dtype=bool)
        self.goal_mem = np.zeros((memory_size, input_dims), dtype=np.float32)

    def add_experience(self, state, action, reward, next_state, done, goal):
        """
        Adds new experience to the memory
        """
        
        #mem: memory
        
        ind = self.counter % self.max_mem_size

        self.state_mem[ind] = state
        self.action_mem[ind] = action
        self.reward_mem[ind] = reward
        self.next_state_mem[ind] = next_state
        self.terminal_mem[ind] = done
        self.goal_mem[ind] = goal

        self.counter += 1

    def get_random_experience(self, batch_size):
        """
        Returns any random memory from the experience replay memory
        """
        ind_random = np.random.choice(min(self.counter, self.max_mem_size), batch_size)

        state_random = self.state_mem[ind_random]
        action_random = self.action_mem[ind_random]
        reward_random = self.reward_memind_random]
        next_state_random = self.next_state_mem[ind_random]
        done_random = self.terminal_mem[ind_random]
        goal_random = self.goal_mem[ind_random]

        return state_random, action_random, reward_random, next_state_random, done_random, goal_random
